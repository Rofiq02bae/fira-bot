# üöÄ Training BERT Model dengan Google Colab

Panduan lengkap untuk melatih model BERT menggunakan GPU gratis dari Google Colab.

## üìã Mengapa Menggunakan Google Colab?

Melatih model BERT memerlukan:
- **GPU yang lumayan besar** (minimum 8GB VRAM)
- **Waktu training yang lama** (30-90 menit tergantung dataset)
- **Resource komputasi tinggi**

Jika Anda **tidak memiliki GPU**, gunakan **Google Colab** dengan GPU **Tesla T4 gratis**!

---

## üéØ Langkah-langkah Training

### **a) Buat Notebook Baru**

1. Buka [Google Colab](https://colab.research.google.com/)
2. Klik **File > New notebook**
3. Atau upload file `BERT_TRAINING_COLAB.ipynb` dari repository

### **b) Klik 'Runtime' > 'Change runtime type' > Ubah ke GPU T4**

1. Klik menu **Runtime** di atas
2. Pilih **Change runtime type**
3. Di dropdown **Hardware accelerator**, pilih **GPU**
4. Pilih GPU Type: **T4** (gratis)
5. Klik **Save**

![GPU Setup](https://i.imgur.com/example.png)

‚úÖ **Verifikasi GPU:** Jalankan `!nvidia-smi` untuk memastikan GPU aktif

### **c) Copy paste isi file `collab_requirements.txt` ke cell pertama**

1. Buka file [`collab_requirements.txt`](collab_requirements.txt)
2. Copy semua isi file
3. Paste ke **cell pertama** di Colab notebook
4. Atau gunakan code ini:

```python
# ==================== INSTALL DEPENDENCIES ====================
print("üîÑ Installing dependencies...")
print("‚è±Ô∏è  Estimasi waktu: 2-3 menit\n")

!pip install -q transformers datasets accelerate torch pandas
!pip install -q scikit-learn numpy tqdm

print("\n" + "="*60)
print("üöÄ Colab environment ready for BERT training!")
print("‚úÖ All dependencies installed successfully!")
print("="*60)
print("\n‚ö†Ô∏è  PENTING: Restart Session sekarang!")
print("    Klik: Runtime > Restart session")
print("="*60)
```

### **d) Running cell pertama, tunggu semua dependensi selesai di install, lalu restart session**

1. Klik tombol **Play (‚ñ∂Ô∏è)** di cell pertama atau tekan **Shift+Enter**
2. Tunggu hingga semua package terinstall (~2-3 menit)
3. Setelah muncul pesan "Restart Session sekarang!"
4. Klik **Runtime > Restart session**
5. Konfirmasi dengan klik **Restart**

‚ö†Ô∏è **PENTING:** Restart session wajib dilakukan untuk menerapkan perubahan library!

### **e) Copy paste file `bert_training.py` atau `bert_train.ipynb` ke cell berikutnya**

**Option 1: Menggunakan Notebook Lengkap (Recommended)**

Upload file `BERT_TRAINING_COLAB.ipynb` yang sudah disediakan - sudah include semua code!

**Option 2: Manual Copy-Paste**

1. Buka file [`training/bert_training.py`](training/bert_training.py)
2. Copy seluruh code
3. Paste ke **cell kedua** (setelah restart session)

**Option 3: Clone Repository**

```python
# Clone repository
!git clone https://github.com/Rofiq02bae/fira-bot.git
%cd fira-bot

# Import training script
from training import bert_training
```

### **f) Pilih model yang akan digunakan, ada 3 pilihan**

Ubah variable `MODEL_CHOICE` di code:

```python
# üéØ PILIH MODEL (1, 2, atau 3)
MODEL_CHOICE = 1  # Default: IndoBERT Base
```

**Pilihan Model:**

| Model | Nama | Ukuran | Kecepatan | Akurasi | Waktu Training |
|-------|------|--------|-----------|---------|----------------|
| **1** | IndoBERT Base | ~500MB | Sedang | **Tinggi** ‚≠ê | 6-7 min |
| **2** | IndoBERT Lite | ~200MB | **Cepat** ‚ö° | Sedang | 5-6 min |
| **3** | bert-base-indonesian-522M | ~700MB | Lambat | Tinggi | 7-8 min |

**Rekomendasi:**
- ‚úÖ **Model 1 (IndoBERT Base)** - Untuk production/deployment
- ‚ö° **Model 2 (IndoBERT Lite)** - Untuk testing/cepat
- üåç **Model 3 (bert-base-indonesian-522M)** - Jika perlu bahasa kompleks

### **g) Import `dataset_training.csv` ke Google Colab**

**Method 1: Upload Manual (Recommended)**

```python
from google.colab import files

# Upload dataset
print("üìÇ Upload file dataset_training.csv")
uploaded = files.upload()

# Verify
import pandas as pd
df = pd.read_csv('dataset_training.csv')
print(f"‚úÖ Dataset loaded: {len(df)} rows")
```

**Method 2: From Google Drive**

```python
from google.colab import drive

# Mount Drive
drive.mount('/content/drive')

# Copy dataset
!cp /content/drive/MyDrive/dataset_training.csv ./
```

**Method 3: Clone dari GitHub**

Jika dataset sudah di-commit ke repository:

```python
!git clone https://github.com/Rofiq02bae/fira-bot.git
%cd fira-bot
# Dataset sudah ada di: data/dataset/dataset_training.csv
```

### **h) Running cell kedua dan tunggu sekitar 7 menit**

1. Klik **Play (‚ñ∂Ô∏è)** di cell training atau tekan **Shift+Enter**
2. Training akan dimulai dengan progress bar


**Proses Training:**
```
üìÇ Loading dataset...
‚úÖ Dataset loaded: 2847 samples
   Unique intents: 156
   Training samples: 2277
   Validation samples: 570

üîÑ Loading model: indobenchmark/indobert-base-p1
‚úÖ Model loaded successfully!

üîÑ Tokenizing dataset...
‚úÖ Tokenization complete!

üöÄ TRAINING STARTED!
‚è±Ô∏è  Estimasi waktu: ~30-60 min

Epoch 1/3:
  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 143/143 [05:23<00:00]
  Loss: 0.3421, Accuracy: 0.8956
  
Epoch 2/3:
  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 143/143 [05:18<00:00]
  Loss: 0.1842, Accuracy: 0.9412

Epoch 3/3:
  Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 143/143 [05:15<00:00]
  Loss: 0.0921, Accuracy: 0.9756

‚úÖ TRAINING COMPLETED!
‚è±Ô∏è  Total time: 27.43 minutes
```

üí° **Tips:**
- Jangan tutup tab browser selama training
- Bisa minimize tab tapi jangan close
- Monitor progress di output cell

### **i) Running cell ketiga untuk download model**

Setelah training selesai:

```python
# ==================== DOWNLOAD MODEL ====================
from google.colab import files
import shutil

print("üì¶ Preparing model for download...")

# Zip the model
shutil.make_archive('bert_model', 'zip', './bert_model')

# Download
files.download('bert_model.zip')

print("‚úÖ MODEL DOWNLOADED!")
```

File `bert_model.zip` akan otomatis terdownload (~500-700 MB)

‚è±Ô∏è Waktu download: **2-5 menit** (tergantung koneksi internet)

### **j) Ekstrak model ke `data/bert_model`**

**Di komputer local Anda:**

1. **Extract ZIP file:**
   ```bash
   # Windows
   Extract bert_model.zip menggunakan Windows Explorer
   # Atau dengan PowerShell
   Expand-Archive bert_model.zip -DestinationPath bert_model
   ```

2. **Copy ke project directory:**
   ```bash

   # Copy semua isi folder
   Copy-Item -Path "bert_model\*" -Destination "data\bert_model\" -Recurse
   ```

3. **Verify struktur folder:**
   ```
   data/bert_model/
   ‚îú‚îÄ‚îÄ config.json
   ‚îú‚îÄ‚îÄ model.safetensors
   ‚îú‚îÄ‚îÄ tokenizer.json
   ‚îú‚îÄ‚îÄ tokenizer_config.json
   ‚îú‚îÄ‚îÄ special_tokens_map.json
   ‚îú‚îÄ‚îÄ vocab.txt
   ‚îî‚îÄ‚îÄ label_encoder.pkl
   ```

4. **Test model berhasil di-load:**
   ```bash
   python -c "from main import get_hybrid_nlu; service = get_hybrid_nlu(); print('‚úÖ Model loaded!')"
   ```

### **k) Jalankan server**

Setelah model berhasil di-extract dan di-copy:

```bash
# Aktifkan virtual environment (jika ada)
.\.venv\Scripts\Activate.ps1

# Jalankan FastAPI server
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

**Output yang diharapkan:**
```
üöÄ Starting Hybrid Chatbot API (Modular Version)...
üìÇ Checking model files...
‚úÖ lstm_model: data/lstm_models/chatbot_model.h5 - EXISTS
‚úÖ bert_folder: data/bert_model - EXISTS
‚úÖ dataset: data/dataset/dataset_training.csv - EXISTS

üîÑ Initializing modular hybrid service...
‚úÖ LSTM Model loaded successfully!
‚úÖ Fine-tuned BERT loaded successfully!
‚úÖ Modular hybrid service initialized!

INFO:     Uvicorn running on http://0.0.0.0:8000
INFO:     Application startup complete.
```

**Test API:**

1. Buka browser: http://localhost:8000/docs
2. Test endpoint `/api/chat`:
   ```json
   {
     "text": "hai"
   }
   ```

3. Response:
   ```json
   {
     "original_text": "hai",
     "predicted_intent": "salam",
     "confidence": 0.956,
     "response": "halo, ada yang bisa saya bantu",
     "method_used": "hybrid_fusion"
   }
   ```

‚úÖ **SELESAI!** Model BERT Anda sudah berjalan di server local!

---

## üìä Monitoring Training

### GPU Usage

Monitor GPU selama training:

```python
# Run di cell terpisah
!nvidia-smi -l 2  # Update setiap 2 detik
```

Stop dengan: Runtime > Interrupt execution

### Training Metrics

Yang perlu diperhatikan:

| Metric | Good | Warning | Bad |
|--------|------|---------|-----|
| **Loss** | Menurun setiap epoch | Stagnan | Naik |
| **Accuracy** | Naik setiap epoch | Stagnan | Turun |
| **Val Loss** | Similar to Train Loss | Sedikit lebih tinggi | Jauh lebih tinggi (overfit) |

**Contoh Good Training:**
```
Epoch 1: Loss=0.45, Acc=0.82, Val_Loss=0.48
Epoch 2: Loss=0.28, Acc=0.89, Val_Loss=0.31
Epoch 3: Loss=0.18, Acc=0.93, Val_Loss=0.22
```

‚úÖ Loss menurun, Accuracy naik, Validation loss mengikuti

---

## üêõ Troubleshooting

### ‚ùå GPU Not Available

**Problem:** GPU tidak terdeteksi

**Solution:**
1. Runtime > Change runtime type
2. Hardware accelerator: **GPU**
3. Save
4. Runtime > Restart runtime

### ‚ùå CUDA Out of Memory

**Problem:** GPU memory habis

**Solution:**
```python
# Kurangi batch size
BATCH_SIZE = 8  # dari 16 ke 8
# Atau
BATCH_SIZE = 4  # jika masih error
```

### ‚ùå Session Disconnected

**Problem:** Colab disconnect saat training

**Solution:**
- Reconnect dan re-run cells
- Backup model ke Google Drive secara berkala
- Gunakan code untuk keep alive (lihat tips di bawah)

### ‚ùå Dataset Not Found

**Problem:** File dataset tidak ditemukan

**Solution:**
```python
# Upload ulang dataset
from google.colab import files
uploaded = files.upload()

# Verify
!ls -lh dataset_training.csv
```

### ‚ùå Download Failed

**Problem:** Download model gagal/incomplete

**Solution:**
```python
# Backup ke Google Drive dulu
from google.colab import drive
drive.mount('/content/drive')

!cp -r bert_model /content/drive/MyDrive/

# Download dari Drive nanti
```

---

## üí° Tips & Tricks

### 1. Keep Colab Alive

Prevent auto-disconnect dengan JavaScript di browser console (F12):

```javascript
function ClickConnect(){
    console.log("Keeping alive...");
    document.querySelector("colab-connect-button").click();
}
setInterval(ClickConnect, 60000);  // Every 60 seconds
```

### 2. Auto-Backup ke Google Drive

Tambahkan di akhir training:

```python
from google.colab import drive
drive.mount('/content/drive')

# Backup otomatis
!cp -r bert_model /content/drive/MyDrive/fira-bot-backup/
print("‚úÖ Backup complete!")
```

### 3. Monitor via Email

Get notifikasi saat training selesai:

```python
# Install
!pip install -q notify-send-py

# At end of training
from notify_send import notify
notify("Training Complete!", "BERT model training finished!")
```

### 4. Multiple Model Training

Train beberapa konfigurasi sekaligus:

```python
configs = [
    {'model': 1, 'epochs': 3, 'batch': 16},  # IndoBERT Base
    {'model': 2, 'epochs': 3, 'batch': 16},  # IndoBERT Lite
]

for config in configs:
    print(f"Training: {config}")
    # Run training with config
    # Save with different names
```

---

## üìà Hasil Training yang Baik

### Model Size

File yang dihasilkan:

| File | Size | Description |
|------|------|-------------|
| `model.safetensors` | ~400-600 MB | Model weights |
| `config.json` | ~1 KB | Model configuration |
| `tokenizer.json` | ~500 KB | Tokenizer |
| `vocab.txt` | ~200 KB | Vocabulary |
| `label_encoder.pkl` | ~5-50 KB | Intent encoder |
| **Total** | **~500-700 MB** | Full model |

---

## ‚úÖ Checklist

### Before Training

- [ ] Akun Google sudah login
- [ ] GPU T4 sudah aktif di Colab
- [ ] Dependencies sudah terinstall
- [ ] Session sudah di-restart
- [ ] Dataset CSV sudah di-upload
- [ ] Model choice sudah dipilih

### During Training

- [ ] Monitor training progress
- [ ] Check GPU usage (`!nvidia-smi`)
- [ ] Pastikan loss menurun
- [ ] Pastikan accuracy naik
- [ ] Jangan tutup tab browser

### After Training

- [ ] Model sudah di-download
- [ ] Ekstrak ZIP file
- [ ] Copy ke `data/bert_model/`
- [ ] Verify file structure
- [ ] Test model loading
- [ ] Run server dan test API
- [ ] Backup model (optional)

---

## üìö Resources

- [Google Colab Documentation](https://colab.research.google.com/notebooks/intro.ipynb)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [IndoBERT Model](https://huggingface.co/indobenchmark/indobert-base-p1)
- [File Lengkap: COLAB_GUIDE.md](COLAB_GUIDE.md)

---

## üéâ Success!

Jika semua langkah berhasil:

‚úÖ Model BERT sudah ter-training  
‚úÖ Model sudah di-download  
‚úÖ Model sudah di-copy ke project  
‚úÖ Server berjalan dengan baik  
‚úÖ API bisa memprediksi dengan akurat  

**Congratulations!** üéä

Anda sekarang punya chatbot dengan:
- üöÄ LSTM (fast response)
- üéØ BERT (high accuracy)
- ü§ñ Hybrid (best of both worlds)

---

**Made with ‚ù§Ô∏è for fira-bot project**

Last updated: November 2025 oleh Rofiq02bae 
please add star
