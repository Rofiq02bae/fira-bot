# Runtime dependencies only (inference + API + Telegram bot)
# Training/notebooks/test tooling intentionally excluded.

# Use PyPI for most packages, but force CPU-only PyTorch wheels (prevents huge CUDA/NVIDIA downloads).
--index-url https://pypi.org/simple
--extra-index-url https://download.pytorch.org/whl/cpu

fastapi
uvicorn
pydantic
requests

# Models (hybrid: BERT + LSTM)
transformers==4.35.2
torch==2.2.2+cpu

# LSTM inference runtime
tensorflow==2.20.0
numpy
scikit-learn

# Dataset loader for intent mappings
pandas

# Bot + env
python-telegram-bot==20.7
python-dotenv
aiohttp
